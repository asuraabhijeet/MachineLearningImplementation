# -*- coding: utf-8 -*-
"""VeryLowResourceMT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19zV5TtlQ6n_a81lugwDZ27gY7XJS5Aok
"""

!pip install fairseq



!git clone https://github.com/rsennrich/subword-nmt.git

!pip install sacremoses

!git clone https://github.com/moses-smt/mosesdecoder.git

!pip install sacrebleu

!mkdir base_train_data

# Commented out IPython magic to ensure Python compatibility.
!gzip -d ./base_train_data/train_dsb_hsb_62564.dsb.gz
!gzip -d ./base_train_data/train_dsb_hsb_62564.hsb.gz

# %cd base_train_data
!tar -xf devtest_dsb_hsb_2022.tar.gz
# %cd ..



!gzip -d ./base_train_data/train_dsb_hsb_62564.hsb.gz

# Commented out IPython magic to ensure Python compatibility.
# %cd base_train_data
# %cd train_data

!tar -xf devtest_dsb_hsb_2022.tar.gz
# !tar -xf lowres_unsup_testsets.tar.gz

cat /content/train_data/TestSets_lowres_unsup_22/test_dsb_hsb.hsb_src.xml | \
    grep -v '<url>' | \
    grep -v '<talkid>' | \
    grep -v '<keywords>' | \
    sed -e 's/<title>//g' | \
    sed -e 's/<\/title>//g' | \
    sed -e 's/<description>//g' | \
    sed -e 's/<\/description>//g' | > test.hsb

# Commented out IPython magic to ensure Python compatibility.
# !mv *.* ./train_data
# %cd ..

! head -10 ./train_data/train_dsb_hsb_62564.dsb

! head -10 ./train_data/train_dsb_hsb_62564.hsb

! wc -l ./train_data/dev_dsb_hsb_new.dsb

! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < ./base_train_data/train_dsb_hsb_62564.hsb > ./base_train_data/train_dsb_hsb_62564.tok.hsb
! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < ./base_train_data/valid_dsb_hsb.hsb > ./base_train_data/valid_dsb_hsb.tok.hsb
! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < ./base_train_data/dev_dsb_hsb_new.hsb > ./base_train_data/dev_dsb_hsb_new.tok.hsb
# ! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < ./base_train_data/test.hsb > ./base_train_data/test.tok.hsb



!head -10 ./train_data/train_dsb_hsb_62564.tok.hsb

! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < ./base_train_data/train_dsb_hsb_62564.dsb > ./base_train_data/train_dsb_hsb_62564.tok.dsb
! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < ./base_train_data/valid_dsb_hsb.dsb > ./base_train_data/valid_dsb_hsb.tok.dsb
! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < ./base_train_data/dev_dsb_hsb_new.dsb > ./base_train_data/dev_dsb_hsb_new.tok.dsb
# ! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < ./base_train_data/test.dsb > ./base_train_data/test.tok.dsb

!head -10 ./train_data/train_dsb_hsb_62564.tok.dsb

! ./mosesdecoder/scripts/training/clean-corpus-n.perl base_train_data/train_dsb_hsb_62564.tok dsb hsb base_train_data/train_dsb_hsb_62564.tok.clean 1 180

! ./mosesdecoder/scripts/training/clean-corpus-n.perl base_train_data/valid_dsb_hsb.tok dsb hsb base_train_data/valid_dsb_hsb.tok.clean 1 180
! ./mosesdecoder/scripts/training/clean-corpus-n.perl base_train_data/dev_dsb_hsb_new.tok dsb hsb base_train_data/dev_dsb_hsb_new.tok.clean 1 180



!head -10 train_data/train_dsb_hsb_62564.tok.clean.dsb

!python ./subword-nmt/subword_nmt/learn_bpe.py -s 16000 < base_train_data/train_dsb_hsb_62564.tok.clean.dsb > base_train_data/train_dsb_hsb_62564.code.dsb



!python ./subword-nmt/subword_nmt/learn_bpe.py -s 16000 < base_train_data/train_dsb_hsb_62564.tok.clean.hsb > base_train_data/train_dsb_hsb_62564.code.hsb

!head -100 train_data/train_dsb_hsb_62564.code.dsb

! python ./subword-nmt/subword_nmt/apply_bpe.py -c ./base_train_data/train_dsb_hsb_62564.code.dsb < ./base_train_data/train_dsb_hsb_62564.tok.clean.dsb > train.dsb
! python ./subword-nmt/subword_nmt/apply_bpe.py -c ./base_train_data/train_dsb_hsb_62564.code.dsb < ./base_train_data/valid_dsb_hsb.tok.clean.dsb > valid.dsb
! python ./subword-nmt/subword_nmt/apply_bpe.py -c ./base_train_data/train_dsb_hsb_62564.code.dsb < ./base_train_data/dev_dsb_hsb_new.tok.clean.dsb > dev.dsb
# ! python ./subword-nmt/subword_nmt/apply_bpe.py -c ./base_train_data/train_dsb_hsb_62564.code.dsb < ./base_train_data/test.tok.clean.dsb > dev.dsb

!head -10 train.dsb

!mkdir data1

! python ./subword-nmt/subword_nmt/apply_bpe.py -c ./base_train_data/train_dsb_hsb_62564.code.hsb < ./base_train_data/train_dsb_hsb_62564.tok.clean.hsb > train.hsb
! python ./subword-nmt/subword_nmt/apply_bpe.py -c ./base_train_data/train_dsb_hsb_62564.code.hsb < ./base_train_data/valid_dsb_hsb.tok.clean.hsb > valid.hsb
! python ./subword-nmt/subword_nmt/apply_bpe.py -c ./base_train_data/train_dsb_hsb_62564.code.hsb < ./base_train_data/dev_dsb_hsb_new.tok.clean.hsb > dev.hsb
# ! python ./subword-nmt/subword_nmt/apply_bpe.py -c ./base_train_data/train_dsb_hsb_62564.code.dsb < ./base_train_data/test.tok.clean.hsb > dev.hsb



!fairseq-preprocess --source-lang hsb --target-lang dsb \
    --joined-dictionary\
    --trainpref train \
    --validpref valid\
    --testpref dev\
    --destdir base_data \
    --workers 20

from google.colab import drive
drive.mount('/content/drive')

!mkdir  transformer_checkpoint_hsb_dsb

!mkdir transformer_checkpoint_hsb_dsb_log

!CUDA_VISIBLE_DEVICES=0 fairseq-train base_data \
    --arch transformer_iwslt_de_en \
    --source-lang hsb --target-lang dsb \
    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.1 \
    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \
    --dropout 0.3 --weight-decay 0.0001 \
    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \
    --max-tokens 4096 \
    --patience 5 \
    --eval-bleu \
    --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' \
    --eval-bleu-detok moses \
    --eval-bleu-remove-bpe \
    --eval-bleu-print-samples \
    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \
    --save-dir transformer_checkpoint_hsb_dsb --no-epoch-checkpoints | tee transformer_checkpoint_hsb_dsb_log/train_transformer.out

!CUDA_VISIBLE_DEVICES=0 fairseq-interactive base_data \
    --path /content/drive/MyDrive/base_hsb_dsb/checkpoint_best.pt \
    --beam 5 --remove-bpe \
    --input dev.hsb | tee dev.hsb-dsb.base_dsb.sys

!head -10 dev.dsb-hsb.base_dsb.hypo.sys
!head -10 base_train_data/dev_dsb_hsb_new.dsb

!grep ^H dev.hsb-dsb.base_dsb.sys | cut -f3- > dev.hsb-dsb.base_dsb.tok.sys

# Remove tokenization and truecasing
!cat dev.hsb-dsb.base_dsb.tok.sys | mosesdecoder/scripts/recaser/detruecase.perl | mosesdecoder/scripts/tokenizer/detokenizer.perl -l en > dev.dsb-hsb.base_dsb.hypo.sys

#(9) Automatic Evaluation
# Score the test set with sacrebleu
!cat  dev.dsb-hsb.base_dsb.hypo.sys | sacrebleu base_train_data/dev_dsb_hsb_new.dsb
# !cat dev.dsb-hsb.base_dsb.hypo.sys | sacrebleu  dev.dsb

!mkdir transformer_checkpoint_dsb_hsb transformer_checkpoint_dsb_hsb_log

"""

```
# This is formatted as code
```
DSB - HSB Backtranslation

"""

!CUDA_VISIBLE_DEVICES=0 fairseq-train base_data \
    --arch transformer_iwslt_de_en \
    --source-lang dsb --target-lang hsb \
    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.1 \
    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \
    --dropout 0.3 --weight-decay 0.0001 \
    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \
    --max-tokens 4096 \
    --patience 5 \
    --eval-bleu \
    --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' \
    --eval-bleu-detok moses \
    --eval-bleu-remove-bpe \
    --eval-bleu-print-samples \
    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \
    --save-dir transformer_checkpoint_dsb_hsb --no-epoch-checkpoints | tee  transformer_checkpoint_dsb_hsb_log/train_transformer.out

!CUDA_VISIBLE_DEVICES=0 fairseq-interactive base_data \
    --path /content/drive/MyDrive/dsb_hsb/checkpoint_best.pt \
    --beam 5 --remove-bpe \
    --input dev.dsb | tee dev.transformer.hsb.sys

!grep ^H dev.transformer.hsb.sys | cut -f3- > dev.tiny.hsb.tok_transformer.sys

# Remove tokenization and truecasing
!cat dev.tiny.hsb.tok_transformer.sys | mosesdecoder/scripts/recaser/detruecase.perl | mosesdecoder/scripts/tokenizer/detokenizer.perl -l en > dev.tiny.hsb._transformer_hypo.sys

#(9) Automatic Evaluation
# Score the test set with sacrebleu
!cat  dev.tiny.hsb._transformer_hypo.sys | sacrebleu base_train_data/dev_dsb_hsb_new.hsb
# !cat  dev.tiny.hsb._transformer_hypo.sys | sacrebleu dev.hsb

!head -10 dev.dsb-hsb.hsb.hypo.tok.sys

# !head -10 dev.hsb
!head -10  train_data/dev_dsb_hsb_new.hsb

!mkdir dsb_monolingual

# Commented out IPython magic to ensure Python compatibility.
# %cd dsb_monolingual/

!gzip -d 66408_DSB_monolingual.txt.gz
!gzip -d 8815_DSB_wikipedia_2021.txt.gz
!gzip -d mono.dsb.gz

# Commented out IPython magic to ensure Python compatibility.
# !cat 66408_DSB_monolingual.txt 8815_DSB_wikipedia_2021.txt mono.dsb >> mono_final.dsb
# %cd ..

!wc -l ./dsb_monolingual/66408_DSB_monolingual.txt
!wc -l ./dsb_monolingual/8815_DSB_wikipedia_2021.txt
!wc -l ./dsb_monolingual/mono.dsb
!wc -l ./dsb_monolingual/mono_final.dsb

! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < ./dsb_monolingual/mono_final.dsb > ./dsb_monolingual/mono.tok.dsb

! python ./subword-nmt/subword_nmt/apply_bpe.py -c ./base_train_data/train_dsb_hsb_62564.code.dsb < ./dsb_monolingual/mono.tok.dsb > ./dsb_monolingual/mono_final_train.dsb
# ! python ./subword-nmt/subword_nmt/apply_bpe.py -c ./train_data/synthetic.code.dsb < ./dsb_monolingual/mono.tok.dsb > ./dsb_monolingual/mono_final_train.dsb

!rm -r mono_dsb_preprrocess_data

!fairseq-preprocess --source-lang dsb --target-lang hsb \
--only-source \
    --joined-dictionary \
    --srcdict base_data/dict.dsb.txt \
    --testpref ./dsb_monolingual/mono_final_train \
    --destdir base_data/mono_dsb_preprrocess_data \
    --workers 20 \

!cp base_data/dict.hsb.txt base_data/mono_dsb_preprrocess_data/dict.hsb.txt

!CUDA_VISIBLE_DEVICES=0 fairseq-interactive base_data/mono_dsb_preprrocess_data \
    --path /content/drive/MyDrive/dsb_hsb/checkpoint_best.pt \
    --beam 5 --remove-bpe \
    --input ./dsb_monolingual/mono_final_train.dsb | tee /content/drive/MyDrive/dsb_hsb/mono_final_train.hsb

!mv dsb_mono.sys mono_final_train.hsb

!grep ^H /content/drive/MyDrive/dsb_hsb/mono_final_train.hsb | cut -f3- > dsb_mono_hypo.hsb

!cat dsb_mono_hypo.hsb | mosesdecoder/scripts/recaser/detruecase.perl | mosesdecoder/scripts/tokenizer/detokenizer.perl -l en > dsb_mono_synthetic.hsb

!mkdir train_data

# !wc -l dsb_mono_synthetic.hsb
!wc -l synthetic.dsb
!wc -l synthetic.hsb

# Commented out IPython magic to ensure Python compatibility.
!gzip -d ./train_data/train_dsb_hsb_62564.dsb.gz
!gzip -d ./train_data/train_dsb_hsb_62564.hsb.gz

# %cd train_data
!tar -xf devtest_dsb_hsb_2022.tar.gz
# %cd ..

!cat train_data/train_dsb_hsb_62564.hsb  dsb_mono_synthetic.hsb >> synthetic.hsb

!cat train_data/train_dsb_hsb_62564.dsb train_data/mono_final.dsb >> synthetic.dsb

! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < synthetic.hsb > train_data/synthetic.tok.hsb
! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < synthetic.dsb > train_data/synthetic.tok.dsb

! ./mosesdecoder/scripts/training/clean-corpus-n.perl train_data/synthetic.tok dsb hsb train_data/synthetic.tok.clean 1 180

! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < train_data/valid_dsb_hsb.hsb > train_data/valid_dsb_hsb.tok.hsb
! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < train_data/valid_dsb_hsb.dsb > train_data/valid_dsb_hsb.tok.dsb

! ./mosesdecoder/scripts/training/clean-corpus-n.perl train_data/valid_dsb_hsb.tok dsb hsb train_data/valid_dsb_hsb.tok.clean 1 180

! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < train_data/dev_dsb_hsb_new.hsb > train_data/dev_dsb_hsb_new.tok.hsb
! ./mosesdecoder/scripts/tokenizer/tokenizer.perl -threads 8 -l en  < train_data/dev_dsb_hsb_new.dsb > train_data/dev_dsb_hsb_new.tok.dsb

! ./mosesdecoder/scripts/training/clean-corpus-n.perl train_data/dev_dsb_hsb_new.tok dsb hsb train_data/dev_dsb_hsb_new.tok.clean 1 180

!python ./subword-nmt/subword_nmt/learn_bpe.py -s 16000 < train_data/synthetic.tok.clean.hsb > train_data/synthetic.code.hsb
!python ./subword-nmt/subword_nmt/learn_bpe.py -s 16000 < train_data/synthetic.tok.clean.dsb > train_data/synthetic.code.dsb



! python ./subword-nmt/subword_nmt/apply_bpe.py -c train_data/synthetic.code.hsb < train_data/synthetic.tok.clean.hsb > synthetic_train.hsb
! python ./subword-nmt/subword_nmt/apply_bpe.py -c train_data/synthetic.code.hsb < ./train_data/valid_dsb_hsb.tok.clean.hsb > valid1.hsb
! python ./subword-nmt/subword_nmt/apply_bpe.py -c train_data/synthetic.code.hsb < ./train_data/dev_dsb_hsb_new.tok.clean.hsb > dev1.hsb

! python ./subword-nmt/subword_nmt/apply_bpe.py -c train_data/synthetic.code.dsb < train_data/synthetic.tok.clean.dsb > synthetic_train.dsb
! python ./subword-nmt/subword_nmt/apply_bpe.py -c train_data/synthetic.code.dsb < ./train_data/valid_dsb_hsb.tok.clean.dsb > valid1.dsb
! python ./subword-nmt/subword_nmt/apply_bpe.py -c train_data/synthetic.code.dsb < ./train_data/dev_dsb_hsb_new.tok.clean.dsb > dev1.dsb

!fairseq-preprocess --source-lang hsb --target-lang dsb \
    --joined-dictionary\
    --trainpref synthetic_train \
    --validpref valid1\
    --testpref dev1\
    --destdir data \
    --workers 20

!mkdir transformer_checkpoint_hsb_dsb
!mkdir transformer_log_hsb_dsb

!CUDA_VISIBLE_DEVICES=0 fairseq-train data \
    --arch transformer_iwslt_de_en \
    --source-lang hsb --target-lang dsb \
    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.1 \
    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \
    --dropout 0.3 --weight-decay 0.0001 \
    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \
    --max-tokens 4096 \
    --patience 5 \
    --eval-bleu \
    --eval-bleu-args '{"beam": 5, "max_len_a": 1.2, "max_len_b": 10}' \
    --eval-bleu-detok moses \
    --eval-bleu-remove-bpe \
    --eval-bleu-print-samples \
    --best-checkpoint-metric bleu --maximize-best-checkpoint-metric \
    --save-dir /content/drive/MyDrive/hsb_dsb_bt --no-epoch-checkpoints | tee transformer_log_hsb_dsb/train_transformer.out

!CUDA_VISIBLE_DEVICES=0 fairseq-interactive data \
    --path /content/drive/MyDrive/hsb_dsb_bt/checkpoint_best.pt \
    --beam 5 --remove-bpe \
    --input dev1.hsb | tee dev.dsb-hsb.dsb_v1.sys

!grep ^H dev.dsb-hsb.dsb_v1.sys | cut -f3- > dev.dsb-hsb.dsb.tok_tiny.sys

# Remove tokenization and truecasing
!cat dev.dsb-hsb.dsb.tok_tiny.sys | mosesdecoder/scripts/recaser/detruecase.perl | mosesdecoder/scripts/tokenizer/detokenizer.perl -l en > dev.dsb-hsb.dsb.hypo_tiny.sys

#(9) Automatic Evaluation
# Score the test set with sacrebleu
!cat  dev.dsb-hsb.dsb.hypo_tiny.sys | sacrebleu train_data/dev_dsb_hsb_new.dsb
# !cat  dev.dsb-hsb.dsb.hypo_tiny.sys | sacrebleu dev1.dsb

!head -10 train_data/dev_dsb_hsb_new.dsb

!head -10 dev.dsb-hsb.dsb.hypo_tiny.sys

!gzip checkpoint_hsb_dsb/checkpoint_best.pt