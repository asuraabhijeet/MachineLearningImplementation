{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import libraies"
      ],
      "metadata": {
        "id": "AsCh48e8ol9D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e2XYXmYOhYYv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read train and test data files"
      ],
      "metadata": {
        "id": "A26ybz51oxAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(file):\n",
        "\tFile = open(file, \"r\")\n",
        "\tdata = {\"id\": [], \"corpus\": [],  \"sentence\": [],\"token\" :[], \"complexity\": []}\n",
        "\t\n",
        "\tFile.readline()\n",
        "\twhile True:\n",
        "\t\tline = File.readline()\n",
        "\t\tif len(line) == 0:\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\tline = line.split()\n",
        "\t\tdata[\"id\"].append(line[0])\n",
        "\t\tdata[\"corpus\"].append(line[1])\n",
        "\n",
        "\t\tdata[\"sentence\"].append(' '.join(line[2:-2]))\n",
        "\t\tdata[\"token\"].append(line[-2])\n",
        "\t\tdata[\"complexity\"].append(float(line[-1]))\n",
        "\treturn pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "o5hUP3FxlOmW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = read_file('train.txt')\n",
        "# test = read_file('test.txt' )"
      ],
      "metadata": {
        "id": "UofekH3ElwYg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IvpglP-hmhHw",
        "outputId": "a4f50921-da9f-4d9d-d861-07147f34c675"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               id corpus  \\\n",
              "0  3ZLW647WALVGE8EBR50EGUBPU4P32A  bible   \n",
              "1  34R0BODSP1ZBN3DVY8J8XSIY551E5C  bible   \n",
              "2  3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  bible   \n",
              "3  3BFNCI9LYKQN09BHXHH9CLSX5KP738  bible   \n",
              "4  3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2  bible   \n",
              "\n",
              "                                            sentence     token  complexity  \n",
              "0  Behold, there came up out of the river seven c...     river    0.000000  \n",
              "1  I am a fellow bondservant with you and with yo...  brothers    0.000000  \n",
              "2  The man, the lord of the land, said to us, 'By...  brothers    0.050000  \n",
              "3  Shimei had sixteen sons and six daughters; but...  brothers    0.150000  \n",
              "4               \"He has put my brothers far from me.  brothers    0.263889  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8e2efc6-b934-4cde-afde-363ad4c05c25\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>corpus</th>\n",
              "      <th>sentence</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3ZLW647WALVGE8EBR50EGUBPU4P32A</td>\n",
              "      <td>bible</td>\n",
              "      <td>Behold, there came up out of the river seven c...</td>\n",
              "      <td>river</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34R0BODSP1ZBN3DVY8J8XSIY551E5C</td>\n",
              "      <td>bible</td>\n",
              "      <td>I am a fellow bondservant with you and with yo...</td>\n",
              "      <td>brothers</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3S1WOPCJFGTJU2SGNAN2Y213N6WJE3</td>\n",
              "      <td>bible</td>\n",
              "      <td>The man, the lord of the land, said to us, 'By...</td>\n",
              "      <td>brothers</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3BFNCI9LYKQN09BHXHH9CLSX5KP738</td>\n",
              "      <td>bible</td>\n",
              "      <td>Shimei had sixteen sons and six daughters; but...</td>\n",
              "      <td>brothers</td>\n",
              "      <td>0.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2</td>\n",
              "      <td>bible</td>\n",
              "      <td>\"He has put my brothers far from me.</td>\n",
              "      <td>brothers</td>\n",
              "      <td>0.263889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8e2efc6-b934-4cde-afde-363ad4c05c25')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8e2efc6-b934-4cde-afde-363ad4c05c25 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8e2efc6-b934-4cde-afde-363ad4c05c25');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning and Preprocessing Data"
      ],
      "metadata": {
        "id": "7NKXczKTpBub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSXRQ_IUmq6l",
        "outputId": "6bcc4d1b-853b-454d-95a1-c28de33900c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer() \n",
        "def lemmatize(text):\n",
        "\tlemmas = [lemmatizer.lemmatize(word) for word in word_tokenize(text)] \n",
        "\treturn \" \".join(lemmas)\n",
        "\n",
        "# remove stopwords\n",
        "def remove_stopwords(text, token):\n",
        "\twords = [w for w in word_tokenize(text) if (w not in stopwords.words('english')) or w in list(word_tokenize(token))]\n",
        "\treturn \" \".join(words)"
      ],
      "metadata": {
        "id": "WxPIEk0wnOD7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "\t\n",
        "\tdata[\"token\"] = data['token'].astype(str)\n",
        "\n",
        "\t# lower case\n",
        "\tdata['sentence'] = data['sentence'].apply(lambda x: x.lower())\n",
        "\tdata['token'] = data['token'].apply(lambda x: x.lower())\n",
        "\n",
        "\t# remove punctuation\n",
        "\ttranslator = str.maketrans('', '', string.punctuation)\n",
        "\tdata['sentence'] = data['sentence'].apply(lambda x: x.translate(translator))\n",
        "\tdata['token'] = data['token'].apply(lambda x: x.translate(translator))\n",
        "\n",
        "\t# remove stopwords only if token != a stopword\n",
        "\ttry:\n",
        "\t\tnltk.data.find('corpora/stopwords')\n",
        "\texcept LookupError:\n",
        "\t\tnltk.download('stopwords')\n",
        "\n",
        "\tdata['sentence'] = data.apply(lambda x: remove_stopwords(x['sentence'], x['token']) , axis=1)\n",
        "\t\n",
        "\t# lemmatize\n",
        "\tdata['sentence'] = data['sentence'].apply(lambda x: lemmatize(x))\n",
        "\tdata['token'] = data['token'].apply(lambda x: lemmatize(x))\n",
        "\n",
        "\treturn data"
      ],
      "metadata": {
        "id": "NPn8qXjYnTu4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = preprocess(train)\n",
        "# test_data = preprocess(test)"
      ],
      "metadata": {
        "id": "m48yVf7nnpZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c65534e3-f84c-489e-b5ae-bc7a7941d1c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7PwPbptYolOt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wb27FlX6nsNf",
        "outputId": "ee302e76-35d2-45c6-e47a-75fb6ea3edd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               id corpus  \\\n",
              "0  3ZLW647WALVGE8EBR50EGUBPU4P32A  bible   \n",
              "1  34R0BODSP1ZBN3DVY8J8XSIY551E5C  bible   \n",
              "2  3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  bible   \n",
              "3  3BFNCI9LYKQN09BHXHH9CLSX5KP738  bible   \n",
              "4  3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2  bible   \n",
              "\n",
              "                                            sentence    token  complexity  \n",
              "0  behold came river seven cattle sleek fat fed m...    river    0.000000  \n",
              "1  fellow bondservant brother prophet keep word book  brother    0.000000  \n",
              "2  man lord land said u know honest men leave one...  brother    0.050000  \n",
              "3  shimei sixteen son six daughter brother didnt ...  brother    0.150000  \n",
              "4                                    put brother far  brother    0.263889  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e0da0a7-11d0-4169-bc70-d2c6ddab4a78\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>corpus</th>\n",
              "      <th>sentence</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3ZLW647WALVGE8EBR50EGUBPU4P32A</td>\n",
              "      <td>bible</td>\n",
              "      <td>behold came river seven cattle sleek fat fed m...</td>\n",
              "      <td>river</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34R0BODSP1ZBN3DVY8J8XSIY551E5C</td>\n",
              "      <td>bible</td>\n",
              "      <td>fellow bondservant brother prophet keep word book</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3S1WOPCJFGTJU2SGNAN2Y213N6WJE3</td>\n",
              "      <td>bible</td>\n",
              "      <td>man lord land said u know honest men leave one...</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3BFNCI9LYKQN09BHXHH9CLSX5KP738</td>\n",
              "      <td>bible</td>\n",
              "      <td>shimei sixteen son six daughter brother didnt ...</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2</td>\n",
              "      <td>bible</td>\n",
              "      <td>put brother far</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.263889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e0da0a7-11d0-4169-bc70-d2c6ddab4a78')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e0da0a7-11d0-4169-bc70-d2c6ddab4a78 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e0da0a7-11d0-4169-bc70-d2c6ddab4a78');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating new Features for data"
      ],
      "metadata": {
        "id": "PlbrUAEkpIFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['token_length'] = data['token'].str.len()\n",
        "# test_data['token_length'] = test_data['token'].str.len()\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x12SDpwQpGXg",
        "outputId": "d76c6eed-c0f6-49b0-dc34-eda997435320"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               id corpus  \\\n",
              "0  3ZLW647WALVGE8EBR50EGUBPU4P32A  bible   \n",
              "1  34R0BODSP1ZBN3DVY8J8XSIY551E5C  bible   \n",
              "2  3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  bible   \n",
              "3  3BFNCI9LYKQN09BHXHH9CLSX5KP738  bible   \n",
              "4  3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2  bible   \n",
              "\n",
              "                                            sentence    token  complexity  \\\n",
              "0  behold came river seven cattle sleek fat fed m...    river    0.000000   \n",
              "1  fellow bondservant brother prophet keep word book  brother    0.000000   \n",
              "2  man lord land said u know honest men leave one...  brother    0.050000   \n",
              "3  shimei sixteen son six daughter brother didnt ...  brother    0.150000   \n",
              "4                                    put brother far  brother    0.263889   \n",
              "\n",
              "   token_length  \n",
              "0             5  \n",
              "1             7  \n",
              "2             7  \n",
              "3             7  \n",
              "4             7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87fe09ef-55ac-445d-9fdb-8a4d7d18fcd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>corpus</th>\n",
              "      <th>sentence</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "      <th>token_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3ZLW647WALVGE8EBR50EGUBPU4P32A</td>\n",
              "      <td>bible</td>\n",
              "      <td>behold came river seven cattle sleek fat fed m...</td>\n",
              "      <td>river</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34R0BODSP1ZBN3DVY8J8XSIY551E5C</td>\n",
              "      <td>bible</td>\n",
              "      <td>fellow bondservant brother prophet keep word book</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3S1WOPCJFGTJU2SGNAN2Y213N6WJE3</td>\n",
              "      <td>bible</td>\n",
              "      <td>man lord land said u know honest men leave one...</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3BFNCI9LYKQN09BHXHH9CLSX5KP738</td>\n",
              "      <td>bible</td>\n",
              "      <td>shimei sixteen son six daughter brother didnt ...</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3G5RUKN2EC3YIWSKUXZ8ZVH95R49N2</td>\n",
              "      <td>bible</td>\n",
              "      <td>put brother far</td>\n",
              "      <td>brother</td>\n",
              "      <td>0.263889</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87fe09ef-55ac-445d-9fdb-8a4d7d18fcd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87fe09ef-55ac-445d-9fdb-8a4d7d18fcd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87fe09ef-55ac-445d-9fdb-8a4d7d18fcd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def syllable_count(word):\n",
        "    word = word.lower()\n",
        "    count = 0\n",
        "    vowels = \"aeiouy\"\n",
        "    if word[0] in vowels:\n",
        "        count += 1\n",
        "    for index in range(1, len(word)):\n",
        "        if word[index] in vowels and word[index - 1] not in vowels:\n",
        "            count += 1\n",
        "    if word.endswith(\"e\"):\n",
        "        count -= 1\n",
        "    if count == 0:\n",
        "        count += 1\n",
        "    return count"
      ],
      "metadata": {
        "id": "Yy0Tyki6pr9B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['syllables'] = data['token'].apply(lambda x: syllable_count(x) )\n",
        "# test_data['syllables'] = test_data['token'].apply(lambda x: syllable_count(x) )"
      ],
      "metadata": {
        "id": "OU2UoxBupxme"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip -d embeddings\n",
        "!rm glove.6B.zip\n",
        "!rm embeddings/glove.6B.50d.txt\n",
        "!rm embeddings/glove.6B.100d.txt\n",
        "!rm embeddings/glove.6B.200d.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCl4R5YmsJKw",
        "outputId": "acad74f9-21f7-447b-db57-b5c1f41e7773"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-21 17:45:13--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-12-21 17:45:13--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-12-21 17:45:14--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.35MB/s    in 2m 51s  \n",
            "\n",
            "2022-12-21 17:48:05 (4.81 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: embeddings/glove.6B.50d.txt  \n",
            "  inflating: embeddings/glove.6B.100d.txt  \n",
            "  inflating: embeddings/glove.6B.200d.txt  \n",
            "  inflating: embeddings/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['token'] = data['token'].astype(str)\n",
        "data['sentence'] = data['sentence'].astype(str)\n",
        "\n",
        "# test_data['token'] = test_data['token'].astype(str)\n",
        "# test_data['sentence'] = test_data['sentence'].astype(str)"
      ],
      "metadata": {
        "id": "KTdn4cF0sZik"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Split training set into validation and train dataset."
      ],
      "metadata": {
        "id": "Ync5ar1qpgsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, validate_set = train_test_split(train, test_size=0.2, random_state=12)\n",
        "print(len(train))\n",
        "print(len(validate_set))"
      ],
      "metadata": {
        "id": "OJgNI94nt1hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b22db8d-ad9d-4a40-c9e9-ed400cf7f084"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6129\n",
            "1533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentence_list = list(train['sentence'])\n",
        "train_complexity_list = list(train['complexity'])\n",
        "train_token_list = list(train['token'])\n",
        "\n",
        "# test_sentence_list = list(test['sentence'])\n",
        "# test_complexity_list = list(test['complexity'])\n",
        "# test_token_list = list(test['token'])\n",
        "\n",
        "validate_set_sentence_list = list(validate_set['sentence'])\n",
        "validate_set_complexity_list = list(validate_set['complexity'])\n",
        "validate_set_token_list = list(validate_set['token'])\n",
        "\n",
        "print(len(train_token_list))\n",
        "# print(len(test_sentence_list))\n",
        "print(len(validate_set_sentence_list))"
      ],
      "metadata": {
        "id": "csKlnBoIvLrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc8bd01-251f-4667-e5a1-b88ead3d41fa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6129\n",
            "1533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Embedding from Glove Embeddings"
      ],
      "metadata": {
        "id": "gvDOjqVMpxhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "  return word_to_vec_map\n",
        "\n",
        "word_to_vec_map = read_glove_vector('embeddings/glove.6B.300d.txt')\n",
        "\n",
        "# get embeddings, and pad till max_len\n",
        "def get_embeddings(sentences, max_len=0):\n",
        "    sentence_emb = []\n",
        "    for s in sentences:\n",
        "\n",
        "        temp_sent_emb = [ word_to_vec_map[x] if x in word_to_vec_map else np.full((300,), np.nan) for x in s.split() ]\n",
        "        mean_emb = np.nanmean(np.array(temp_sent_emb), axis=0)\n",
        "\n",
        "        temp_sent_emb = np.array([ mean_emb if np.isnan(x[0]) else x for x in temp_sent_emb ])\n",
        "        temp_sent_emb = np.concatenate((temp_sent_emb, np.zeros((max_len-temp_sent_emb.shape[0],300))))\n",
        "\n",
        "        sentence_emb.append(temp_sent_emb)\n",
        "\n",
        "    return np.array(sentence_emb)"
      ],
      "metadata": {
        "id": "1iq5vIB5vfxw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Padding for sentences"
      ],
      "metadata": {
        "id": "cJBbR5ZRqH5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# max len for the sentence used for padding\n",
        "max_len_sent =max(max([len(s.split()) for s in train_sentence_list]),\n",
        "    max([len(s.split()) for s in validate_set_sentence_list]))\n",
        "print(max_len_sent)\n",
        "\n",
        "max_len_token = max(max([len(s.split()) for s in train_token_list]) ,\n",
        "                    max([len(s.split()) for s in validate_set_token_list])) \n",
        "print(max_len_token)\n"
      ],
      "metadata": {
        "id": "AKQhMsL1wZv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e8db27d-18a1-49ef-d94e-0e992f1008b9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sent_emb = get_embeddings(train_sentence_list, max_len_sent)\n",
        "# test_sent_emb = get_embeddings(test_sentence_list, max_len_sent)\n",
        "val_sentence_emb = get_embeddings(validate_set_sentence_list, max_len_sent )\n",
        "\n",
        "print(\"Sentence embedding shape train : {}\".format(train_sent_emb.shape))\n",
        "# print(\"Sentence embedding shape test : {}\".format(test_sent_emb.shape))\n",
        "print(\"Sentence embedding shape val : {}\".format(val_sentence_emb.shape))"
      ],
      "metadata": {
        "id": "7WsbiLIYxnaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5ac03c-4ef2-418d-a0b2-4681b9537058"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence embedding shape train : (6129, 123, 300)\n",
            "Sentence embedding shape val : (1533, 123, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Positional data values from token : Location of token in senetence"
      ],
      "metadata": {
        "id": "A7HhZsyJsfS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_token_data =   [ \n",
        "                        [ \n",
        "                            len(s.split(t)[0].split()), \n",
        "                            len(t.split())\n",
        "                        ]\n",
        "                        for s,t in zip(train_sentence_list, train_token_list) \n",
        "                    ]\n",
        "\n",
        "# test_token_data =   [ \n",
        "#                         [ \n",
        "#                             len(s.split(t)[0].split()), \n",
        "#                             len(t.split())\n",
        "#                         ]\n",
        "#                         for s,t in zip(test_sentence_list, test_token_list) \n",
        "#                     ]\n",
        "\n",
        "validate_token_data =   [ \n",
        "                        [ \n",
        "                            len(s.split(t)[0].split()), \n",
        "                            len(t.split())\n",
        "                        ]\n",
        "                        for s,t in zip(validate_set_sentence_list, validate_set_token_list) \n",
        "                    ]\n",
        "\n"
      ],
      "metadata": {
        "id": "QGr3rA0A4oSL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_train = train[['token_length', 'syllables'\n",
        "                        ]].values\n",
        "\n",
        "# features_test = test[['token_length', 'syllables',\n",
        "#                         ]].values\n",
        "features_validate_set = validate_set[['token_length', 'syllables',\n",
        "                        ]].values\n",
        "\n",
        "print(len(features_train))"
      ],
      "metadata": {
        "id": "PnLv9frR74aW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7269f6c9-ce60-4345-e131-83895e94226c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FFN(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, \n",
        "        hidden_size,\n",
        "        output_size,\n",
        "        rate,\n",
        "        softmax=False,\n",
        "    ):\n",
        "        super(FFN, self).__init__()\n",
        "\n",
        "        self.layer1 = tf.keras.layers.Dense(hidden_size, activation=\"relu\")  # (batch_size, hidden_size)\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        self.layer2 = tf.keras.layers.Dense(output_size, activation= \"softmax\" if softmax is True else None)  # (batch_size, output_size)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        return self.layer2(self.dropout(self.layer1(x), training=training) ) \n"
      ],
      "metadata": {
        "id": "CG1ksAi6AOnH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OurModelBiLSTM(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        lstm_units,\n",
        "        hidden_size,\n",
        "        random_seed,\n",
        "        seq_len,\n",
        "        embedding_size,\n",
        "        rate=0.25\n",
        "        ):\n",
        "        \"\"\"\n",
        "        hidden_size - for FFN\n",
        "        \"\"\"\n",
        "\n",
        "        super(OurModelBiLSTM, self).__init__()\n",
        "\n",
        "        tf.random.set_seed(random_seed)\n",
        "        self.random_seed = random_seed\n",
        "        self.lstm_units = lstm_units\n",
        "\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "                tf.keras.layers.LSTM(self.lstm_units, return_sequences=True), input_shape=(seq_len,embedding_size)\n",
        "            )\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=rate)\n",
        "\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.dense = tf.keras.layers.Dense(2*self.lstm_units)\n",
        "        self.getWeights = FFN(hidden_size, 3, rate, softmax=True)\n",
        "        self.final_layer = FFN(hidden_size, 1, rate)\n",
        "\n",
        "    \n",
        "    # one fwd pass on the model\n",
        "    def call(self, input_seq, token_position, feature_emb, training=False):\n",
        "        \"\"\"\n",
        "        input_seq : [batch_size, seq_len, embedding_size]\n",
        "        token_position = [batch_size, 2] - [start,length] for tokens for which complexity is to be predicted\n",
        "        \"\"\"\n",
        "\n",
        "        # bi-lstm pass\n",
        "        bilstm_output = self.bilstm(input_seq)\n",
        "\n",
        "        # bilstm_output = self.bilstm(input_seq)      #(batch_size, seq_len, 2*lstm_units)\n",
        "        bilstm_output = self.dropout(bilstm_output, training=training)\n",
        "\n",
        "        # extract token embeddings    \n",
        "        # for each example we have start token and length\n",
        "        # we take mean of these embeddings position\n",
        "\n",
        "        token_emb = tf.stack(\n",
        "                [tf.reduce_mean(tf.gather(i, tf.range(j[0],j[0]+j[1]), axis=0), axis=0) for i,j in zip(bilstm_output,token_position) ]\n",
        "            )   # (batch_size, 2*lstm_units)\n",
        "\n",
        "        # combine all embeddings - take mean\n",
        "        added_emb = tf.reduce_mean(bilstm_output, axis=1)    # (batch_size, 2*lstm_units)\n",
        "        \n",
        "        # feature_emb - (batch_shape, features)\n",
        "        feature_emb = self.dense(feature_emb)           # (batch_size, 2*lstm_units)\n",
        "        # feature_emb = tf.cast(feature_emb, tf.float32)\n",
        "\n",
        "        # get weights\n",
        "        # weights = self.getWeights(self.layernorm(tf.add_n([token_emb,added_emb, feature_emb])), training)    # (batch_size, 3)\n",
        "        weights = self.getWeights(self.layernorm(tf.concat([token_emb,added_emb, feature_emb], axis=1)), training)    # (batch_size, 3)\n",
        "\n",
        "        # generate attenton-based final embeddings\n",
        "        # final_emb = weights[0]*token_emb + weights[1]*added_emb + weights[3]*features_emb\n",
        "\n",
        "        final_emb = tf.zeros(shape=(), dtype=tf.dtypes.float32)   # (bacth_size, 2*lstm_units)\n",
        "        final_emb += tf.expand_dims(weights[:, 0], axis=1) * token_emb\n",
        "        final_emb += tf.expand_dims(weights[:, 1], axis=1) * added_emb\n",
        "        final_emb += tf.expand_dims(weights[:, 2], axis=1) * feature_emb\n",
        "\n",
        "        # output complexity\n",
        "        final_output = self.final_layer(final_emb, training)\n",
        "\n",
        "        return final_output\n",
        "\n",
        "    # loss function\n",
        "    def loss_function(self, real, pred):\n",
        "        loss_ = tf.keras.losses.MSE(real, pred)\n",
        "        l = tf.reduce_mean(loss_)\n",
        "        return l\n",
        "\n",
        "    # set optimizer\n",
        "    def compile(self, optimizer):\n",
        "        super(OurModelBiLSTM, self).compile()\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "\n",
        "    # train step - fwd pass + back prop + update model weights\n",
        "    # @tf.function() - may not work beacuse zip is used\n",
        "    def train_step(self, input_seq, token_position, y, feature_emb):\n",
        "        training=True\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            y_pred = self(input_seq, token_position, feature_emb, training)  \n",
        "            loss = self.loss_function(tf.reshape(y,(-1,1)), y_pred)\n",
        "\n",
        "        # calculate gradients\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "\n",
        "        # update model weights using gradients\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # fit funtion of model\n",
        "    def _fit(\n",
        "        self, \n",
        "        input_seq_data, \n",
        "        token_position_data, \n",
        "        feature_emb_data,\n",
        "        complexity, \n",
        "        epochs, \n",
        "        batch_size,\n",
        "        val_input_seq_data=None,\n",
        "        val_token_position_data=None,\n",
        "        val_feature_emb_data=None,\n",
        "        val_complexity=None\n",
        "        ):\n",
        "\n",
        "        # create tensorflow dataset\n",
        "        tf_data = tf.data.Dataset.from_tensor_slices((input_seq_data, token_position_data, feature_emb_data, complexity))\n",
        "\n",
        "        # shuffle and batch\n",
        "        tf_data = tf_data.shuffle(100000, seed=self.random_seed).batch(batch_size)\n",
        "\n",
        "        train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "        loss_train = {\"MSE\": []}\n",
        "        loss_val = {\"MSE\": []}\n",
        "\n",
        "        #training starts\n",
        "        for epoch in range(epochs):\n",
        "            start = time.time()\n",
        "            \n",
        "            # reset state for mean loss\n",
        "            train_loss.reset_states()\n",
        "\n",
        "            # loop over batches\n",
        "            for step, x in tf_data.enumerate():\n",
        "\n",
        "                # get inputs for model\n",
        "                input_seq = x[0]\n",
        "                token_position = x[1]\n",
        "                feature_emb = x[2]\n",
        "                y = x[3]\n",
        "\n",
        "                # call trainstep\n",
        "                loss = self.train_step(input_seq, token_position, y, feature_emb)\n",
        "                train_loss(loss)\n",
        "\n",
        "            loss_train[\"MSE\"].append(train_loss.result().numpy())\n",
        "            print(\"Epoch {} loss  MSE: {}, time taken: {:.2f}s\".format(epoch + 1, loss_train[\"MSE\"][-1], time.time() - start))\n",
        "\n",
        "            # validation if provided\n",
        "            if (val_input_seq_data is not None):\n",
        "                val_pred = self._predict(val_input_seq_data, val_token_position_data, val_feature_emb_data)\n",
        "                loss_val[\"MSE\"].append(self.loss_function(tf.reshape(val_complexity, (-1,1)), val_pred).numpy())\n",
        "                print(\"Validation loss MSE : {}\".format(loss_val[\"MSE\"][-1]))\n",
        "\n",
        "\n",
        "        if (val_input_seq_data is not None):\n",
        "            return loss_train, loss_val\n",
        "        return loss_train\n",
        "\n",
        "    \n",
        "    # predict function\n",
        "    def _predict(self, input_seq_data, token_position_data, feature_emb_data):\n",
        "        \n",
        "        # create tensorflow dataset\n",
        "        tf_data = tf.data.Dataset.from_tensor_slices((input_seq_data, token_position_data, feature_emb_data))\n",
        "\n",
        "        # batch for memory constraints\n",
        "        tf_data = tf_data.batch(512)\n",
        "\n",
        "        pred_list = []\n",
        "        for step, x in tf_data.enumerate():\n",
        "            # get inputs for model\n",
        "            input_seq = x[0]\n",
        "            token_position = x[1]\n",
        "            feature_emb = x[2]\n",
        "\n",
        "            pred_list.append(self(input_seq, token_position, feature_emb))\n",
        "        return tf.concat(pred_list, axis=0)\n",
        "     "
      ],
      "metadata": {
        "id": "cXLbaLZjAQwo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_units=20\n",
        "hidden_size=10\n",
        "random_seed=12\n",
        "seq_len=max_len_sent\n",
        "embedding_size=300\n",
        "rate=0.4\n",
        "epochs=20\n",
        "batch_size=32\n",
        "model = OurModelBiLSTM(lstm_units=lstm_units, hidden_size=hidden_size, random_seed=random_seed, seq_len=seq_len, embedding_size=embedding_size, rate=rate)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005))\n",
        "\n",
        "loss = model._fit ( train_sent_emb, \n",
        "                    train_token_data,\n",
        "                    feature_emb_data = features_train,\n",
        "                    complexity = train_complexity_list,\n",
        "                    epochs=epochs, \n",
        "                    batch_size=batch_size,\n",
        "                    val_input_seq_data=val_sentence_emb,\n",
        "                    val_token_position_data = validate_token_data,\n",
        "                    val_feature_emb_data = features_validate_set,\n",
        "                    val_complexity = validate_set_complexity_list\n",
        "                )\n",
        "     "
      ],
      "metadata": {
        "id": "76A5rup2BWTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e6563f8-5390-48ae-e799-1cf69d60f496"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss  MSE: 0.023003390058875084, time taken: 38.14s\n",
            "Validation loss MSE : 0.01719142682850361\n",
            "Epoch 2 loss  MSE: 0.013761792331933975, time taken: 31.76s\n",
            "Validation loss MSE : 0.009958258830010891\n",
            "Epoch 3 loss  MSE: 0.011445410549640656, time taken: 31.55s\n",
            "Validation loss MSE : 0.008967380039393902\n",
            "Epoch 4 loss  MSE: 0.01027032732963562, time taken: 31.32s\n",
            "Validation loss MSE : 0.009060914628207684\n",
            "Epoch 5 loss  MSE: 0.009315293282270432, time taken: 31.85s\n",
            "Validation loss MSE : 0.009455887600779533\n",
            "Epoch 6 loss  MSE: 0.009084396064281464, time taken: 31.37s\n",
            "Validation loss MSE : 0.007851263508200645\n",
            "Epoch 7 loss  MSE: 0.008754400536417961, time taken: 35.38s\n",
            "Validation loss MSE : 0.00789842288941145\n",
            "Epoch 8 loss  MSE: 0.008407429791986942, time taken: 31.22s\n",
            "Validation loss MSE : 0.008765201084315777\n",
            "Epoch 9 loss  MSE: 0.008304108865559101, time taken: 31.48s\n",
            "Validation loss MSE : 0.008296521380543709\n",
            "Epoch 10 loss  MSE: 0.007832781411707401, time taken: 30.37s\n",
            "Validation loss MSE : 0.00849013589322567\n",
            "Epoch 11 loss  MSE: 0.008157378993928432, time taken: 30.65s\n",
            "Validation loss MSE : 0.008027281612157822\n",
            "Epoch 12 loss  MSE: 0.007734656799584627, time taken: 31.11s\n",
            "Validation loss MSE : 0.008266291581094265\n",
            "Epoch 13 loss  MSE: 0.007716134190559387, time taken: 31.13s\n",
            "Validation loss MSE : 0.008261996321380138\n",
            "Epoch 14 loss  MSE: 0.007279177661985159, time taken: 31.61s\n",
            "Validation loss MSE : 0.008014846593141556\n",
            "Epoch 15 loss  MSE: 0.007417579647153616, time taken: 30.87s\n",
            "Validation loss MSE : 0.008297363296151161\n",
            "Epoch 16 loss  MSE: 0.00715436739847064, time taken: 32.47s\n",
            "Validation loss MSE : 0.008710034191608429\n",
            "Epoch 17 loss  MSE: 0.007187277544289827, time taken: 33.44s\n",
            "Validation loss MSE : 0.008071939460933208\n",
            "Epoch 18 loss  MSE: 0.006759383250027895, time taken: 33.14s\n",
            "Validation loss MSE : 0.007931357249617577\n",
            "Epoch 19 loss  MSE: 0.0066385045647621155, time taken: 33.00s\n",
            "Validation loss MSE : 0.008197059854865074\n",
            "Epoch 20 loss  MSE: 0.006733778398483992, time taken: 33.25s\n",
            "Validation loss MSE : 0.008541814982891083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = model._predict(test_sent_emb, test_token_data, features_test)\n"
      ],
      "metadata": {
        "id": "Rc5VspOi_O7v"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# mae_score = mean_absolute_error(test_complexity_list, pred)\n",
        "# mae_score"
      ],
      "metadata": {
        "id": "x3tgUdhqXCE6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lr4YvJKhC2T",
        "outputId": "51ac06af-e8b5-4487-99d9-4888af312545"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"our_model_bi_lstm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  multiple                 51360     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           multiple                  0         \n",
            "                                                                 \n",
            " layer_normalization (LayerN  multiple                 240       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  120       \n",
            "                                                                 \n",
            " ffn (FFN)                   multiple                  1243      \n",
            "                                                                 \n",
            " ffn_1 (FFN)                 multiple                  421       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,384\n",
            "Trainable params: 53,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('./my_modal')"
      ],
      "metadata": {
        "id": "HGE0-PsV0Qpx"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}