{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import libraies"
      ],
      "metadata": {
        "id": "AsCh48e8ol9D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e2XYXmYOhYYv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read train and test data files"
      ],
      "metadata": {
        "id": "A26ybz51oxAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(file):\n",
        "\tFile = open(file, \"r\")\n",
        "\tdata = {\"id\": [], \"corpus\": [],  \"sentence\": [],\"token\" :[], \"complexity\": []}\n",
        "\t\n",
        "\tFile.readline()\n",
        "\twhile True:\n",
        "\t\tline = File.readline()\n",
        "\t\tif len(line) == 0:\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\tline = line.split()\n",
        "\t\tdata[\"id\"].append(line[0])\n",
        "\t\tdata[\"corpus\"].append(line[1])\n",
        "\n",
        "\t\tdata[\"sentence\"].append(' '.join(line[2:-2]))\n",
        "\t\tdata[\"token\"].append(line[-2])\n",
        "\t\tdata[\"complexity\"].append(float(line[-1]))\n",
        "\treturn pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "o5hUP3FxlOmW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = read_file('test.txt' )"
      ],
      "metadata": {
        "id": "UofekH3ElwYg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IvpglP-hmhHw",
        "outputId": "77ee528a-63d7-4e4a-b009-676819531b7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               id corpus  \\\n",
              "0  3K8CQCU3KE19US5SN890DFPK3SANWR  bible   \n",
              "1  3Q2T3FD0ON86LCI41NJYV3PN0BW3MV  bible   \n",
              "2  3ULIZ0H1VA5C32JJMKOTQ8Z4GUS51B  bible   \n",
              "3  3BFF0DJK8XCEIOT30ZLBPPSRMZQTSD  bible   \n",
              "4  3QREJ3J433XSBS8QMHAICCR0BQ1LKR  bible   \n",
              "\n",
              "                                            sentence     token  complexity  \n",
              "0  But he, beckoning to them with his hand to be ...      hand    0.000000  \n",
              "1  If I forget you, Jerusalem, let my right hand ...      hand    0.197368  \n",
              "2  the ten sons of Haman the son of Hammedatha, t...      hand    0.200000  \n",
              "3  Let your hand be lifted up above your adversar...      hand    0.267857  \n",
              "4  Abimelech chased him, and he fled before him, ...  entrance    0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d76aacb2-b22e-4183-aa27-e1606e7bc081\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>corpus</th>\n",
              "      <th>sentence</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3K8CQCU3KE19US5SN890DFPK3SANWR</td>\n",
              "      <td>bible</td>\n",
              "      <td>But he, beckoning to them with his hand to be ...</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3Q2T3FD0ON86LCI41NJYV3PN0BW3MV</td>\n",
              "      <td>bible</td>\n",
              "      <td>If I forget you, Jerusalem, let my right hand ...</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.197368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3ULIZ0H1VA5C32JJMKOTQ8Z4GUS51B</td>\n",
              "      <td>bible</td>\n",
              "      <td>the ten sons of Haman the son of Hammedatha, t...</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3BFF0DJK8XCEIOT30ZLBPPSRMZQTSD</td>\n",
              "      <td>bible</td>\n",
              "      <td>Let your hand be lifted up above your adversar...</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.267857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3QREJ3J433XSBS8QMHAICCR0BQ1LKR</td>\n",
              "      <td>bible</td>\n",
              "      <td>Abimelech chased him, and he fled before him, ...</td>\n",
              "      <td>entrance</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d76aacb2-b22e-4183-aa27-e1606e7bc081')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d76aacb2-b22e-4183-aa27-e1606e7bc081 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d76aacb2-b22e-4183-aa27-e1606e7bc081');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data cleaning and Preprocessing Data"
      ],
      "metadata": {
        "id": "7NKXczKTpBub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSXRQ_IUmq6l",
        "outputId": "8e639de9-66c4-4311-f49d-ba5ed255c707"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer() \n",
        "def lemmatize(text):\n",
        "\tlemmas = [lemmatizer.lemmatize(word) for word in word_tokenize(text)] \n",
        "\treturn \" \".join(lemmas)\n",
        "\n",
        "# remove stopwords\n",
        "def remove_stopwords(text, token):\n",
        "\twords = [w for w in word_tokenize(text) if (w not in stopwords.words('english')) or w in list(word_tokenize(token))]\n",
        "\treturn \" \".join(words)"
      ],
      "metadata": {
        "id": "WxPIEk0wnOD7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "\t\n",
        "\tdata[\"token\"] = data['token'].astype(str)\n",
        "\n",
        "\t# lower case\n",
        "\tdata['sentence'] = data['sentence'].apply(lambda x: x.lower())\n",
        "\tdata['token'] = data['token'].apply(lambda x: x.lower())\n",
        "\n",
        "\t# remove punctuation\n",
        "\ttranslator = str.maketrans('', '', string.punctuation)\n",
        "\tdata['sentence'] = data['sentence'].apply(lambda x: x.translate(translator))\n",
        "\tdata['token'] = data['token'].apply(lambda x: x.translate(translator))\n",
        "\n",
        "\t# remove stopwords only if token != a stopword\n",
        "\ttry:\n",
        "\t\tnltk.data.find('corpora/stopwords')\n",
        "\texcept LookupError:\n",
        "\t\tnltk.download('stopwords')\n",
        "\n",
        "\tdata['sentence'] = data.apply(lambda x: remove_stopwords(x['sentence'], x['token']) , axis=1)\n",
        "\t\n",
        "\t# lemmatize\n",
        "\tdata['sentence'] = data['sentence'].apply(lambda x: lemmatize(x))\n",
        "\tdata['token'] = data['token'].apply(lambda x: lemmatize(x))\n",
        "\n",
        "\treturn data"
      ],
      "metadata": {
        "id": "NPn8qXjYnTu4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = preprocess(test)"
      ],
      "metadata": {
        "id": "m48yVf7nnpZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2c1f09-b935-44c1-9493-03d68b61c966"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7PwPbptYolOt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wb27FlX6nsNf",
        "outputId": "83acfdb7-db70-40d3-e4ab-b1782f2ca087"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               id corpus  \\\n",
              "0  3K8CQCU3KE19US5SN890DFPK3SANWR  bible   \n",
              "1  3Q2T3FD0ON86LCI41NJYV3PN0BW3MV  bible   \n",
              "2  3ULIZ0H1VA5C32JJMKOTQ8Z4GUS51B  bible   \n",
              "3  3BFF0DJK8XCEIOT30ZLBPPSRMZQTSD  bible   \n",
              "4  3QREJ3J433XSBS8QMHAICCR0BQ1LKR  bible   \n",
              "\n",
              "                                            sentence     token  complexity  \n",
              "0  beckoning hand silent declared lord brought pr...      hand    0.000000  \n",
              "1       forget jerusalem let right hand forget skill      hand    0.197368  \n",
              "2  ten son haman son hammedatha jew enemy didnt l...      hand    0.200000  \n",
              "3            let hand lifted adversary let enemy cut      hand    0.267857  \n",
              "4  abimelech chased fled many fell wounded even e...  entrance    0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ccd1860b-3417-467f-83f2-b4dd00e91e50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>corpus</th>\n",
              "      <th>sentence</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3K8CQCU3KE19US5SN890DFPK3SANWR</td>\n",
              "      <td>bible</td>\n",
              "      <td>beckoning hand silent declared lord brought pr...</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3Q2T3FD0ON86LCI41NJYV3PN0BW3MV</td>\n",
              "      <td>bible</td>\n",
              "      <td>forget jerusalem let right hand forget skill</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.197368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3ULIZ0H1VA5C32JJMKOTQ8Z4GUS51B</td>\n",
              "      <td>bible</td>\n",
              "      <td>ten son haman son hammedatha jew enemy didnt l...</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3BFF0DJK8XCEIOT30ZLBPPSRMZQTSD</td>\n",
              "      <td>bible</td>\n",
              "      <td>let hand lifted adversary let enemy cut</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.267857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3QREJ3J433XSBS8QMHAICCR0BQ1LKR</td>\n",
              "      <td>bible</td>\n",
              "      <td>abimelech chased fled many fell wounded even e...</td>\n",
              "      <td>entrance</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccd1860b-3417-467f-83f2-b4dd00e91e50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ccd1860b-3417-467f-83f2-b4dd00e91e50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ccd1860b-3417-467f-83f2-b4dd00e91e50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating new Features for data"
      ],
      "metadata": {
        "id": "PlbrUAEkpIFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['token_length'] = test_data['token'].str.len()\n",
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "x12SDpwQpGXg",
        "outputId": "c18777f3-79d8-48d8-9a4b-bd827b335dc8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               id corpus  \\\n",
              "0  3K8CQCU3KE19US5SN890DFPK3SANWR  bible   \n",
              "1  3Q2T3FD0ON86LCI41NJYV3PN0BW3MV  bible   \n",
              "2  3ULIZ0H1VA5C32JJMKOTQ8Z4GUS51B  bible   \n",
              "3  3BFF0DJK8XCEIOT30ZLBPPSRMZQTSD  bible   \n",
              "4  3QREJ3J433XSBS8QMHAICCR0BQ1LKR  bible   \n",
              "\n",
              "                                            sentence     token  complexity  \\\n",
              "0  beckoning hand silent declared lord brought pr...      hand    0.000000   \n",
              "1       forget jerusalem let right hand forget skill      hand    0.197368   \n",
              "2  ten son haman son hammedatha jew enemy didnt l...      hand    0.200000   \n",
              "3            let hand lifted adversary let enemy cut      hand    0.267857   \n",
              "4  abimelech chased fled many fell wounded even e...  entrance    0.000000   \n",
              "\n",
              "   token_length  \n",
              "0             4  \n",
              "1             4  \n",
              "2             4  \n",
              "3             4  \n",
              "4             8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cdbfd90-8a0c-4734-a26b-1be740787778\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>corpus</th>\n",
              "      <th>sentence</th>\n",
              "      <th>token</th>\n",
              "      <th>complexity</th>\n",
              "      <th>token_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3K8CQCU3KE19US5SN890DFPK3SANWR</td>\n",
              "      <td>bible</td>\n",
              "      <td>beckoning hand silent declared lord brought pr...</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3Q2T3FD0ON86LCI41NJYV3PN0BW3MV</td>\n",
              "      <td>bible</td>\n",
              "      <td>forget jerusalem let right hand forget skill</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.197368</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3ULIZ0H1VA5C32JJMKOTQ8Z4GUS51B</td>\n",
              "      <td>bible</td>\n",
              "      <td>ten son haman son hammedatha jew enemy didnt l...</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3BFF0DJK8XCEIOT30ZLBPPSRMZQTSD</td>\n",
              "      <td>bible</td>\n",
              "      <td>let hand lifted adversary let enemy cut</td>\n",
              "      <td>hand</td>\n",
              "      <td>0.267857</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3QREJ3J433XSBS8QMHAICCR0BQ1LKR</td>\n",
              "      <td>bible</td>\n",
              "      <td>abimelech chased fled many fell wounded even e...</td>\n",
              "      <td>entrance</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cdbfd90-8a0c-4734-a26b-1be740787778')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0cdbfd90-8a0c-4734-a26b-1be740787778 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0cdbfd90-8a0c-4734-a26b-1be740787778');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def syllable_count(word):\n",
        "    word = word.lower()\n",
        "    count = 0\n",
        "    vowels = \"aeiouy\"\n",
        "    if word[0] in vowels:\n",
        "        count += 1\n",
        "    for index in range(1, len(word)):\n",
        "        if word[index] in vowels and word[index - 1] not in vowels:\n",
        "            count += 1\n",
        "    if word.endswith(\"e\"):\n",
        "        count -= 1\n",
        "    if count == 0:\n",
        "        count += 1\n",
        "    return count"
      ],
      "metadata": {
        "id": "Yy0Tyki6pr9B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['syllables'] = test_data['token'].apply(lambda x: syllable_count(x) )"
      ],
      "metadata": {
        "id": "OU2UoxBupxme"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip -d embeddings\n",
        "!rm glove.6B.zip\n",
        "!rm embeddings/glove.6B.50d.txt\n",
        "!rm embeddings/glove.6B.100d.txt\n",
        "!rm embeddings/glove.6B.200d.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCl4R5YmsJKw",
        "outputId": "342bed60-bca5-46ce-f9eb-72990666a5bb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-21 18:05:34--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-12-21 18:05:34--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-12-21 18:05:35--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.00MB/s    in 4m 8s   \n",
            "\n",
            "2022-12-21 18:09:43 (3.32 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: embeddings/glove.6B.50d.txt  \n",
            "  inflating: embeddings/glove.6B.100d.txt  \n",
            "  inflating: embeddings/glove.6B.200d.txt  \n",
            "  inflating: embeddings/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_data['token'] = test_data['token'].astype(str)\n",
        "test_data['sentence'] = test_data['sentence'].astype(str)"
      ],
      "metadata": {
        "id": "KTdn4cF0sZik"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_sentence_list = list(test['sentence'])\n",
        "test_complexity_list = list(test['complexity'])\n",
        "test_token_list = list(test['token'])\n"
      ],
      "metadata": {
        "id": "csKlnBoIvLrU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Embedding from Glove Embeddings"
      ],
      "metadata": {
        "id": "gvDOjqVMpxhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "\n",
        "  return word_to_vec_map\n",
        "\n",
        "word_to_vec_map = read_glove_vector('embeddings/glove.6B.300d.txt')\n",
        "\n",
        "# get embeddings, and pad till max_len\n",
        "def get_embeddings(sentences, max_len=0):\n",
        "    sentence_emb = []\n",
        "    for s in sentences:\n",
        "\n",
        "        temp_sent_emb = [ word_to_vec_map[x] if x in word_to_vec_map else np.full((300,), np.nan) for x in s.split() ]\n",
        "        mean_emb = np.nanmean(np.array(temp_sent_emb), axis=0)\n",
        "\n",
        "        temp_sent_emb = np.array([ mean_emb if np.isnan(x[0]) else x for x in temp_sent_emb ])\n",
        "        temp_sent_emb = np.concatenate((temp_sent_emb, np.zeros((max_len-temp_sent_emb.shape[0],300))))\n",
        "\n",
        "        sentence_emb.append(temp_sent_emb)\n",
        "\n",
        "    return np.array(sentence_emb)"
      ],
      "metadata": {
        "id": "1iq5vIB5vfxw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Padding for sentences"
      ],
      "metadata": {
        "id": "cJBbR5ZRqH5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# max len for the sentence used for padding\n",
        "max_len_sent = max([len(s.split()) for s in test_sentence_list])\n",
        "\n",
        "print(max_len_sent)\n",
        "\n"
      ],
      "metadata": {
        "id": "AKQhMsL1wZv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e5de51-438a-469d-c6bc-613b6d649084"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sent_emb = get_embeddings(test_sentence_list, max_len_sent)\n",
        "\n",
        "print(\"Sentence embedding shape test : {}\".format(test_sent_emb.shape))\n"
      ],
      "metadata": {
        "id": "7WsbiLIYxnaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c1f9ea-f4fa-487b-8c64-2b5741db3bc9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence embedding shape test : (917, 115, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Positional data values from token : Location of token in senetence"
      ],
      "metadata": {
        "id": "A7HhZsyJsfS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "test_token_data =   [ \n",
        "                        [ \n",
        "                            len(s.split(t)[0].split()), \n",
        "                            len(t.split())\n",
        "                        ]\n",
        "                        for s,t in zip(test_sentence_list, test_token_list) \n",
        "                    ]\n"
      ],
      "metadata": {
        "id": "QGr3rA0A4oSL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "features_test = test[['token_length', 'syllables',\n",
        "                        ]].values\n"
      ],
      "metadata": {
        "id": "PnLv9frR74aW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FFN(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, \n",
        "        hidden_size,\n",
        "        output_size,\n",
        "        rate,\n",
        "        softmax=False,\n",
        "    ):\n",
        "        super(FFN, self).__init__()\n",
        "\n",
        "        self.layer1 = tf.keras.layers.Dense(hidden_size, activation=\"relu\")  # (batch_size, hidden_size)\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        self.layer2 = tf.keras.layers.Dense(output_size, activation= \"softmax\" if softmax is True else None)  # (batch_size, output_size)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        return self.layer2(self.dropout(self.layer1(x), training=training) ) \n",
        "        # return self.layer2(self.dropout(x, training=training)) \n"
      ],
      "metadata": {
        "id": "CG1ksAi6AOnH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OurModelBiLSTM(tf.keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        lstm_units,\n",
        "        hidden_size,\n",
        "        random_seed,\n",
        "        seq_len,\n",
        "        embedding_size,\n",
        "        rate=0.25\n",
        "        ):\n",
        "        \"\"\"\n",
        "        hidden_size - for FFN\n",
        "        \"\"\"\n",
        "\n",
        "        super(OurModelBiLSTM, self).__init__()\n",
        "\n",
        "        tf.random.set_seed(random_seed)\n",
        "        self.random_seed = random_seed\n",
        "        self.lstm_units = lstm_units\n",
        "\n",
        "        self.bilstm = tf.keras.layers.Bidirectional(\n",
        "                tf.keras.layers.LSTM(self.lstm_units, return_sequences=True), input_shape=(seq_len,embedding_size)\n",
        "            )\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=rate)\n",
        "\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.dense = tf.keras.layers.Dense(2*self.lstm_units)\n",
        "        self.getWeights = FFN(hidden_size, 3, rate, softmax=True)\n",
        "        self.final_layer = FFN(hidden_size, 1, rate)\n",
        "\n",
        "    \n",
        "    # one fwd pass on the model\n",
        "    def call(self, input_seq, token_position, feature_emb, training=False):\n",
        "        \"\"\"\n",
        "        input_seq : [batch_size, seq_len, embedding_size]\n",
        "        token_position = [batch_size, 2] - [start,length] for tokens for which complexity is to be predicted\n",
        "        \"\"\"\n",
        "\n",
        "        # bi-lstm pass\n",
        "        bilstm_output = self.bilstm(input_seq)\n",
        "\n",
        "        # bilstm_output = self.bilstm(input_seq)      #(batch_size, seq_len, 2*lstm_units)\n",
        "        bilstm_output = self.dropout(bilstm_output, training=training)\n",
        "\n",
        "        # extract token embeddings    \n",
        "        # for each example we have start token and length\n",
        "        # we take mean of these embeddings position\n",
        "\n",
        "        token_emb = tf.stack(\n",
        "                [tf.reduce_mean(tf.gather(i, tf.range(j[0],j[0]+j[1]), axis=0), axis=0) for i,j in zip(bilstm_output,token_position) ]\n",
        "            )   # (batch_size, 2*lstm_units)\n",
        "\n",
        "        # combine all embeddings - take mean\n",
        "        added_emb = tf.reduce_mean(bilstm_output, axis=1)    # (batch_size, 2*lstm_units)\n",
        "        \n",
        "        # feature_emb - (batch_shape, features)\n",
        "        feature_emb = self.dense(feature_emb)           # (batch_size, 2*lstm_units)\n",
        "        # feature_emb = tf.cast(feature_emb, tf.float32)\n",
        "\n",
        "        # get weights\n",
        "        weights = self.getWeights(self.layernorm(tf.concat([token_emb,added_emb, feature_emb], axis=1)), training)    # (batch_size, 3)\n",
        "\n",
        "        # generate attenton-based final embeddings\n",
        "        # final_emb = weights[0]*token_emb + weights[1]*added_emb + weights[3]*features_emb\n",
        "\n",
        "        final_emb = tf.zeros(shape=(), dtype=tf.dtypes.float32)   # (bacth_size, 2*lstm_units)\n",
        "        final_emb += tf.expand_dims(weights[:, 0], axis=1) * token_emb\n",
        "        final_emb += tf.expand_dims(weights[:, 1], axis=1) * added_emb\n",
        "        final_emb += tf.expand_dims(weights[:, 2], axis=1) * feature_emb\n",
        "\n",
        "        # output complexity\n",
        "        final_output = self.final_layer(final_emb, training)\n",
        "\n",
        "        return final_output\n",
        "\n",
        "    # loss function\n",
        "    def loss_function(self, real, pred):\n",
        "        loss_ = tf.keras.losses.MSE(real, pred)\n",
        "        l = tf.reduce_mean(loss_)\n",
        "        return l\n",
        "\n",
        "    # set optimizer\n",
        "    def compile(self, optimizer):\n",
        "        super(OurModelBiLSTM, self).compile()\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "\n",
        "    # train step - fwd pass + back prop + update model weights\n",
        "    # @tf.function() - may not work beacuse zip is used\n",
        "    def train_step(self, input_seq, token_position, y, feature_emb):\n",
        "        training=True\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            y_pred = self(input_seq, token_position, feature_emb, training)  \n",
        "            loss = self.loss_function(tf.reshape(y,(-1,1)), y_pred)\n",
        "\n",
        "        # calculate gradients\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "\n",
        "        # update model weights using gradients\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # fit funtion of model\n",
        "    def _fit(\n",
        "        self, \n",
        "        input_seq_data, \n",
        "        token_position_data, \n",
        "        feature_emb_data,\n",
        "        complexity, \n",
        "        epochs, \n",
        "        batch_size,\n",
        "        val_input_seq_data=None,\n",
        "        val_token_position_data=None,\n",
        "        val_feature_emb_data=None,\n",
        "        val_complexity=None\n",
        "        ):\n",
        "\n",
        "        # create tensorflow dataset\n",
        "        tf_data = tf.data.Dataset.from_tensor_slices((input_seq_data, token_position_data, feature_emb_data, complexity))\n",
        "\n",
        "        # shuffle and batch\n",
        "        tf_data = tf_data.shuffle(100000, seed=self.random_seed).batch(batch_size)\n",
        "\n",
        "        train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "        loss_train = {\"MSE\": []}\n",
        "        loss_val = {\"MSE\": []}\n",
        "\n",
        "        #training starts\n",
        "        for epoch in range(epochs):\n",
        "            start = time.time()\n",
        "            \n",
        "            # reset state for mean loss\n",
        "            train_loss.reset_states()\n",
        "\n",
        "            # loop over batches\n",
        "            for step, x in tf_data.enumerate():\n",
        "\n",
        "                # get inputs for model\n",
        "                input_seq = x[0]\n",
        "                token_position = x[1]\n",
        "                feature_emb = x[2]\n",
        "                y = x[3]\n",
        "\n",
        "                # call trainstep\n",
        "                loss = self.train_step(input_seq, token_position, y, feature_emb)\n",
        "                train_loss(loss)\n",
        "\n",
        "            loss_train[\"MSE\"].append(train_loss.result().numpy())\n",
        "            print(\"Epoch {} loss  MSE: {}, time taken: {:.2f}s\".format(epoch + 1, loss_train[\"MSE\"][-1], time.time() - start))\n",
        "\n",
        "            # validation if provided\n",
        "            if (val_input_seq_data is not None):\n",
        "                val_pred = self._predict(val_input_seq_data, val_token_position_data, val_feature_emb_data)\n",
        "                loss_val[\"MSE\"].append(self.loss_function(tf.reshape(val_complexity, (-1,1)), val_pred).numpy())\n",
        "                print(\"Validation loss MSE : {}\".format(loss_val[\"MSE\"][-1]))\n",
        "\n",
        "\n",
        "        if (val_input_seq_data is not None):\n",
        "            return loss_train, loss_val\n",
        "        return loss_train\n",
        "\n",
        "    \n",
        "    # predict function\n",
        "    def _predict(self, input_seq_data, token_position_data, feature_emb_data):\n",
        "        \n",
        "        # create tensorflow dataset\n",
        "        tf_data = tf.data.Dataset.from_tensor_slices((input_seq_data, token_position_data, feature_emb_data))\n",
        "\n",
        "        # batch for memory constraints\n",
        "        tf_data = tf_data.batch(512)\n",
        "\n",
        "        pred_list = []\n",
        "        for step, x in tf_data.enumerate():\n",
        "            # get inputs for model\n",
        "            input_seq = x[0]\n",
        "            token_position = x[1]\n",
        "            feature_emb = x[2]\n",
        "\n",
        "            pred_list.append(self(input_seq, token_position, feature_emb))\n",
        "        return tf.concat(pred_list, axis=0)\n",
        "     "
      ],
      "metadata": {
        "id": "cXLbaLZjAQwo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_units=20\n",
        "hidden_size=10\n",
        "random_seed=12\n",
        "seq_len=max_len_sent\n",
        "embedding_size=300\n",
        "rate=0.4\n",
        "epochs=20\n",
        "batch_size=32\n",
        "model2 = OurModelBiLSTM(lstm_units=lstm_units, hidden_size=hidden_size, random_seed=random_seed, seq_len=seq_len, embedding_size=embedding_size, rate=rate)\n",
        "model2.load_weights('./my_modal')\n",
        "pred2 = model2._predict(test_sent_emb, test_token_data, features_test)\n",
        "mae_score = mean_absolute_error(test_complexity_list, pred2)\n",
        "print(mae_score)\n",
        "     "
      ],
      "metadata": {
        "id": "76A5rup2BWTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b537eda-105a-4d08-92e1-6f7c672f35b3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07109030243745054\n"
          ]
        }
      ]
    }
  ]
}